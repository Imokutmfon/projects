{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n\ntrain_dir = \"/kaggle/input/playground-series-s5e6/train.csv\"\ntest_dir = \"/kaggle/input/playground-series-s5e6/test.csv\"\nsample_submission_dir = \"/kaggle/input/playground-series-s5e6/sample_submission.csv\"\n\ndef load_data(directory):\n    data = pd.read_csv(directory)\n    return data\n\ndef split_data(data):\n    data = data.dropna()\n    X = data.drop(columns=['id', 'Fertilizer Name'])\n    y = data['Fertilizer Name']\n    return X, y\n\ndef preprocess_data(X):\n    # Extract numerical columns and categorical columns\n    num_cols = X.select_dtypes(include=np.number).columns.tolist()\n    cat_cols = X.select_dtypes(include='object').columns.tolist()\n    num_features = X[num_cols]\n    num_features_dict = {key: value.to_numpy()[:, tf.newaxis] for key, value in dict(num_features).items()}\n    # Preprocessing model \n    inputs={}\n    for name, column in X.items():\n        if type(column[0]) == str:\n            dtype = tf.string\n        elif name in cat_cols:\n            dtype = tf.int64\n        else:\n            dtype = tf.float32\n        inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n    # Normalize numeric inputs\n    normalizer = tf.keras.layers.Normalization(axis=-1)\n    normalizer.adapt(np.concatenate([value for key, value in sorted(num_features_dict.items())]))\n    num_inputs=[]\n    for name in num_cols:\n        num_inputs.append(inputs[name])\n    num_inputs = tf.keras.layers.Concatenate(axis=-1)(num_inputs)\n    num_normalized = normalizer(num_inputs)\n    preprocessed=[]\n    preprocessed.append(num_normalized)\n    # Categorical features get encoded to one hot encodings\n    for name in cat_cols:\n        vocab = sorted(set(X[name]))\n        print(f'name: {name}')\n        print(f\"vocab: {vocab}\\n\")\n        if type(vocab[0]) is str:\n            lookup = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n        else:\n            lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n        x = inputs[name]\n        x = lookup(x)\n        preprocessed.append(x)\n    preprocessed_result = tf.keras.layers.Concatenate(axis=1)(preprocessed)\n    return inputs, preprocessed_result\n\ndef process_labels(y_train):\n    vocab = sorted(y_train.unique())\n    vocab_tensor = tf.constant(vocab)\n    lookup_table = tf.lookup.StaticHashTable(\n        tf.lookup.KeyValueTensorInitializer(vocab_tensor, tf.range(len(vocab))),\n        default_value=-1\n    )\n    return lookup_table, vocab_tensor\n\ndef build_model(inputs=inputs, preprocessor=preprocessor, model=body):\n    x = preprocessor(inputs)\n    result = body(x)\n    model = tf.keras.Model(inputs, result)\n    model.compile(optimizer='adam',\n                loss=tf.keras.losses.categorical_crossentropy,\n                metrics=['accuracy'])\n    return model\n\n\n\n\ndef master():\n    train_data = load_data(train_dir)\n    test_data = load_data(test_dir)\n    sample_submission = load_data(sample_submission_dir)\n    X_train, y_train = split_data(train_data)\n    inputs, preprocessed_result= preprocess_data(X_train)\n    preprocessor = tf.keras.Model(inputs, preprocessed_result)\n    tf.keras.utils.plot_model(preprocessor, rankdir=\"LR\", show_shapes=True,  show_layer_names=True, to_file=\"preprocessor.png\")\n    label_lookup, label_vocab = process_labels(y_train)\n    # Convert labels to one-hot\n    y_indices = label_lookup.lookup(tf.constant(y_train.values))\n    y_encoded = tf.one_hot(y_indices, depth=len(label_vocab))\n    body = tf.keras.Sequential([\n      tf.keras.layers.Dense(10, activation='relu'),\n      tf.keras.layers.Dense(10, activation='relu'),\n      tf.keras.layers.Dense(len(label_vocab), activation='softmax')\n    ])\n    model = build_model()\n    tf.keras.utils.plot_model(model, show_shapes=True,  show_layer_names=True, to_file=\"model.png\")\n    ds = tf.data.Dataset.from_tensor_slices((\n        dict(X_train),\n        y_encoded\n    ))\n    ds = ds.shuffle(len(y_train)).batch(32)\n    history = model.fit(ds, epochs=5)\n    # For test predictions\n    test_data = load_data(test_dir)\n    X_test = test_data.drop(columns=['id'])\n    \n    # Convert test data to proper format\n    test_dict = {}\n    for name, column in X_test.items():\n        if column.dtype == 'object':\n            test_dict[name] = column.values\n        else:\n            test_dict[name] = column.values\n    \n    # Predict and convert back to original labels\n    predictions = model.predict(test_dict)\n    predicted_indices = tf.argmax(predictions, axis=1)\n    predicted_labels = tf.gather(label_vocab, predicted_indices)\n    \n    # Convert to numpy for final results\n    final_predictions = predicted_labels.numpy().astype(str)\n\n    \nif __name__ == '__main__':\n    master()","metadata":{"_uuid":"8154b162-58c5-4da5-8a02-a8aafcb294de","_cell_guid":"83e5e502-e4c3-4adf-b80f-3e7e6b07c64f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-06-27T06:43:22.284160Z","iopub.execute_input":"2025-06-27T06:43:22.284457Z","iopub.status.idle":"2025-06-27T06:43:22.321415Z","shell.execute_reply.started":"2025-06-27T06:43:22.284438Z","shell.execute_reply":"2025-06-27T06:43:22.320119Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1596728788.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"],"ename":"NameError","evalue":"name 'inputs' is not defined","output_type":"error"}],"execution_count":3}]}